{"meta":{"title":"Hexo","subtitle":"","description":"blog","author":"Tisi is chenying039","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"","slug":"My-New-Post-8","date":"2022-05-31T14:27:09.538Z","updated":"2022-05-31T14:28:41.723Z","comments":true,"path":"2022/05/31/My-New-Post-8/","link":"","permalink":"http://example.com/2022/05/31/My-New-Post-8/","excerpt":"","text":"title: My New Postdate: 2022-05-31 22:27:09tags:《Spark基础环境配置》JDK（1）编译环境软件安装目录（2）上传 jdk-8u171-linux-x64.tar.gz到&#x2F;export&#x2F;softwares&#x2F;目录下安装JDK解压文件至&#x2F;export&#x2F;servers&#x2F;JDK安装目录重命名为jdk（3）配置环境变量重新加载环境变量文件（4）JDK环境验证（5）分发JDK相关文件到node2、31.jdk相关文件分发scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_171&#x2F; root@slave1:&#x2F;export&#x2F;servers&#x2F;scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_171&#x2F; root@slave2:&#x2F;export&#x2F;servers&#x2F;2.分发系统环境变量文件至slave1,slave2scp -r &#x2F;etc&#x2F;profile root@slave1:&#x2F;etc&#x2F;profilescp -r &#x2F;etc&#x2F;profile root@slave2:&#x2F;etc&#x2F;profile3.分别在slave1、slave2上执行source &#x2F;etc&#x2F;profile使环境变量生效Hadoop#上传Hadoop安装包到node1 &#x2F;export&#x2F;server并解压tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz#修改配置文件(进入路径 &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop)①hadoop-env.sh②core-site.xml③hdfs-site.xml④mapred-site.xml⑤yarn-site.xml将hadoop添加到环境变量重新加载环境变量文件一键启动输入 jps 查看Web UI页面验证HDFS集群YARN集群Zookeeper（1）上传压缩包到node1，解压zookeeper的压缩包到&#x2F;export&#x2F;server路径（2）建立软连接：ln -s zookeeper&#x2F; zookeeper，修改配置文件①zoo.cfg（3）添加myid配置创建zkdatas文件存放myidmkdir -p &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;echo 1 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid（4）安装包分发并修改myid的值cd &#x2F;export&#x2F;server&#x2F;scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; node2:$PWDscp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; node3:$PWD①建立软连接，②修改node2 myid&#x3D;2，node3 myid&#x3D;3ln -s zookeeper-3.4.6&#x2F; zookeeperecho 2 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myidln -s zookeeper-3.4.6&#x2F; zookeeperecho 3 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid（6）启动zookeeper服务（三台都启动）&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start","categories":[],"tags":[]},{"title":"","slug":"My-New-Post-4","date":"2022-05-31T13:55:13.542Z","updated":"2022-05-31T13:56:43.423Z","comments":true,"path":"2022/05/31/My-New-Post-4/","link":"","permalink":"http://example.com/2022/05/31/My-New-Post-4/","excerpt":"","text":"title: My New Postdate: 2022-05-31 21:55:13tags:《Spark local&amp;stand alone 配置》1、Anaconda On Linux 安装 (单台服务器脚本安装)（1）安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server:（2）创建虚拟环境 pyspark 基于 python3.8切换到虚拟环境内将spark压缩包上传到 &#x2F;export&#x2F;server 里面 ，解压tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C &#x2F;export&#x2F;server&#x2F;2.spark 安装建立软连接ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark添加环境变量3.重新加载环境变量文件cd &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F;.&#x2F;pyspark进入pyspark界面浏览器访问验证：http://master:4040/Spark（atand-alone） Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装（参考 Local模式下 环境变量的配置内容，确保3台都配置）安装完成：（1）master 节点节点进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 修改以下配置文件①将文件 workers.template 改名为 workers，并配置文件内容将里面的localhost删除，改为：node1node2node3②将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容③配置spark-defaults.conf文件,修改内容④在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:⑤配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory&#x3D;INFO, console 改为log4j.rootCategory&#x3D;WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）（2）master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上（3）在slave1 和 slave2 上做软连接（4）验证进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin 文件目录下重新加载环境变量，启动Spark的Master和Worker进程，启动 start-history-server.sh访问 WebUI界面默认端口master我们设置到了8080如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止可以在日志中查看, 具体顺延到哪个端口上:—Service ‘MasterUI’ could not bind on port 8080. Attempting port 8081.连接到standalone集群&#x2F;&#x2F; 测试代码sc.parallelize(Array(1,2,3,4,5)).map(x&#x3D;&gt; x + 1).collect()查看历史服务器在node1上执行：bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;node1:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 100历史服务器的默认端口是: 18080node1:18080来进入到历史服务器的WEB UI上.","categories":[],"tags":[]},{"title":"","slug":"My-New-Post","date":"2022-05-31T13:32:13.101Z","updated":"2022-05-31T13:34:51.478Z","comments":true,"path":"2022/05/31/My-New-Post/","link":"","permalink":"http://example.com/2022/05/31/My-New-Post/","excerpt":"","text":"title: My New Postdate: 2022-05-31 21:32:13tags:《Spark HA&amp;Yarn配置》Spark（HA）支持的Zookeeper版本为zookeeper-3.7.0版本（1）修改spark-env.sh配置文件删除SPARK_MASTER_HOST&#x3D;node1不固定master节点增加内容：（2）将spark-env.sh分发到node2和node3scp spark-env.sh node2:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;scp spark-env.sh node3:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;关闭当前StandAlone集群(之前需开启配置完成的zookeeper)（4）启动集群:在node1上 启动一个master 和全部workercd &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh在node2上启动一个备用的master进程（5）查看状态：①node1:8080端口状态为ALIVE②在node2上是备用master，当node1启用master时node2状态为standby(8080端口可能会发生顺延)如下端口顺延为8082：关闭node1的master进程，node2master启用其状态切换为ALIVE（6）测试：提交一个spark任务到当前ALIVEmaster上:bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;node1:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000提交后，将ALIVEmaster kill掉，不会影响程序当新的master（即使用node2备用master）接收集群后, 程序继续运行, 正常得到结果5.：HA模式下，主备切换不会影响正在运行的程序Spark(Yarn)1.保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中3.链接到YARN中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）4.client 模式测试运行&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver-memory 512m –executor-memory 512m –num-executors 3 –total-executor-cores 3 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3 测试yarn提交spark任务5.cluster 模式测试&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver-memory 512m –executor-memory 512m –num-executors 3 –total-executor-cores 3 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3通过web UI查看任务运行状态http://master:8080/spark-submit任务提交后，由yarn负责资源调度http://master:19888/spark:部署模式Spark 有多种运行模式， Spark 支持本地运行模式（Local 模式）、独立运行模式（Standalone 模式）、YARN（Yet Another Resource Negotiator）local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程;standalone(集群模式)：典型的Mater&#x2F;slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HAon yarn(集群模式)： 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算Spark运行架构包括：Master（集群资源管理）、Slaves（运行任务的工作节点）、应用程序的控制节点（Driver）和每个工作节点上负责任务的执行进程（Executor）；2、Master是集群资源的管理者（Cluster Manager）。支持：Standalone,Yarn,Mesos；Slaves在spark中被称为Worker，工作节点，；1.Spark的计算模式属于MapReduce,在借鉴Hadoop MapReduce优点的同时很好地解决了MapReduce所面临的问题2.不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活3.Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高4.Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制(函数调用)spark on yarn 的支持两种模式： yarn-cluster：适用于生产环境 yarn-client：适用于交互、调试，希望立即看到app的输出standalone模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。从一定程度上说，该模式是其他两种的基础。","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-31T11:06:11.987Z","updated":"2022-05-31T11:06:11.987Z","comments":true,"path":"2022/05/31/hello-world/","link":"","permalink":"http://example.com/2022/05/31/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}