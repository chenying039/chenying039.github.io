<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2022/05/31/My-New-Post-8/"/>
      <url>/2022/05/31/My-New-Post-8/</url>
      
        <content type="html"><![CDATA[<hr><p>title: My New Post<br>date: 2022-05-31 22:27:09<br>tags:《Spark基础环境配置》<br>JDK<br>（1）编译环境软件安装目录<br>（2）上传 jdk-8u171-linux-x64.tar.gz到&#x2F;export&#x2F;softwares&#x2F;目录下<br>安装JDK<br>解压文件至&#x2F;export&#x2F;servers&#x2F;<br>JDK安装目录重命名为jdk<br>（3）配置环境变量<br>重新加载环境变量文件<br>（4）JDK环境验证<br>（5）分发JDK相关文件到node2、3<br>1.jdk相关文件分发<br>scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_171&#x2F; root@slave1:&#x2F;export&#x2F;servers&#x2F;<br>scp -r &#x2F;export&#x2F;servers&#x2F;jdk1.8.0_171&#x2F; root@slave2:&#x2F;export&#x2F;servers&#x2F;<br>2.分发系统环境变量文件至slave1,slave2<br>scp -r &#x2F;etc&#x2F;profile root@slave1:&#x2F;etc&#x2F;profile<br>scp -r &#x2F;etc&#x2F;profile root@slave2:&#x2F;etc&#x2F;profile<br>3.分别在slave1、slave2上执行source &#x2F;etc&#x2F;profile使环境变量生效<br>Hadoop<br>#上传Hadoop安装包到node1 &#x2F;export&#x2F;server<br>并解压tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz<br>#修改配置文件(进入路径 &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop)<br>①hadoop-env.sh<br>②core-site.xml<br>③hdfs-site.xml<br>④mapred-site.xml<br>⑤yarn-site.xml<br>将hadoop添加到环境变量<br>重新加载环境变量文件<br>一键启动<br>输入 jps 查看<br>Web UI页面验证<br>HDFS集群<br>YARN集群<br>Zookeeper<br>（1）上传压缩包到node1，解压zookeeper的压缩包到&#x2F;export&#x2F;server路径<br>（2）建立软连接：ln -s zookeeper&#x2F; zookeeper，修改配置文件<br>①zoo.cfg<br>（3）添加myid配置<br>创建zkdatas文件存放myid<br>mkdir -p &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;<br>echo 1 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid<br>（4）安装包分发并修改myid的值<br>cd &#x2F;export&#x2F;server&#x2F;<br>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; node2:$PWD<br>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; node3:$PWD<br>①建立软连接，<br>②修改node2 myid&#x3D;2，node3 myid&#x3D;3<br>ln -s zookeeper-3.4.6&#x2F; zookeeper<br>echo 2 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid<br>ln -s zookeeper-3.4.6&#x2F; zookeeper<br>echo 3 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid<br>（6）启动zookeeper服务（三台都启动）<br>&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2022/05/31/My-New-Post-4/"/>
      <url>/2022/05/31/My-New-Post-4/</url>
      
        <content type="html"><![CDATA[<hr><p>title: My New Post<br>date: 2022-05-31 21:55:13<br>tags:《Spark local&amp;stand alone 配置》<br>1、Anaconda On Linux 安装 (单台服务器脚本安装)<br>（1）安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server:<br>（2）创建虚拟环境 pyspark 基于 python3.8<br>切换到虚拟环境内<br>将spark压缩包上传到 &#x2F;export&#x2F;server 里面 ，解压<br>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C &#x2F;export&#x2F;server&#x2F;<br>2.spark 安装<br>建立软连接<br>ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark<br>添加环境变量<br>3.重新加载环境变量文件<br>cd &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F;<br>.&#x2F;pyspark进入pyspark界面<br>浏览器访问验证：<br><a href="http://master:4040/">http://master:4040/</a><br>Spark（atand-alone）</p><p>Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境<br>Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)<br>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装（参考 Local模式下 环境变量的配置内容，确保3台都配置）<br>安装完成：<br>（1）master 节点节点进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 修改以下配置文件<br>①将文件 workers.template 改名为 workers，并配置文件内容<br>将里面的localhost删除，<br>改为：node1<br>node2<br>node3<br>②将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容<br>③配置spark-defaults.conf文件,修改内容<br>④在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:<br>⑤配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory&#x3D;INFO, console 改为<br>log4j.rootCategory&#x3D;WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）<br>（2）master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上<br>（3）在slave1 和 slave2 上做软连接<br>（4）验证<br>进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin 文件目录下<br>重新加载环境变量，启动Spark的Master和Worker进程，启动 start-history-server.sh<br>访问 WebUI界面<br>默认端口master我们设置到了8080<br>如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止<br>可以在日志中查看, 具体顺延到哪个端口上:—<br>Service ‘MasterUI’ could not bind on port 8080. Attempting port 8081.<br>连接到standalone集群<br>&#x2F;&#x2F; 测试代码<br>sc.parallelize(Array(1,2,3,4,5)).map(x&#x3D;&gt; x + 1).collect()<br>查看历史服务器<br>在node1上执行：<br>bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;node1:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 100<br>历史服务器的默认端口是: 18080<br>node1:18080来进入到历史服务器的WEB UI上.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2022/05/31/My-New-Post/"/>
      <url>/2022/05/31/My-New-Post/</url>
      
        <content type="html"><![CDATA[<hr><p>title: My New Post<br>date: 2022-05-31 21:32:13<br>tags:《Spark HA&amp;Yarn配置》<br>Spark（HA）<br>支持的Zookeeper版本为zookeeper-3.7.0版本<br>（1）修改spark-env.sh配置文件<br>删除SPARK_MASTER_HOST&#x3D;node1不固定master节点<br>增加内容：<br>（2）将spark-env.sh分发到node2和node3<br>scp spark-env.sh node2:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;<br>scp spark-env.sh node3:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;<br>关闭当前StandAlone集群(之前需开启配置完成的zookeeper)<br>（4）启动集群:<br>在node1上 启动一个master 和全部worker<br>cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh<br>在node2上启动一个备用的master进程<br>（5）查看状态：①node1:8080端口状态为ALIVE<br>②在node2上是备用master，当node1启用master时node2状态为standby<br>(8080端口可能会发生顺延)<br>如下端口顺延为8082：<br>关闭node1的master进程，node2master启用其状态切换为ALIVE<br>（6）测试：提交一个spark任务到当前ALIVEmaster上:<br>bin&#x2F;spark-submit –master spark:&#x2F;&#x2F;node1:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000<br>提交后，将ALIVEmaster kill掉，不会影响程序<br>当新的master（即使用node2备用master）接收集群后, 程序继续运行, 正常得到结果<br>5.：HA模式下，主备切换不会影响正在运行的程序<br>Spark(Yarn)<br>1.保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中<br>3.链接到YARN中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）<br>4.client 模式测试<br>运行&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver-memory 512m –executor-memory 512m –num-executors 3 –total-executor-cores 3 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3 测试yarn提交spark任务<br>5.cluster 模式测试<br>&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver-memory 512m –executor-memory 512m –num-executors 3 –total-executor-cores 3 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3<br>通过web UI查看任务运行状态<br><a href="http://master:8080/">http://master:8080/</a><br>spark-submit任务提交后，由yarn负责资源调度<br><a href="http://master:19888/">http://master:19888/</a><br>spark:<br>部署模式<br>Spark 有多种运行模式， Spark 支持本地运行模式（Local 模式）、独立运行模式（Standalone 模式）、YARN（Yet Another Resource Negotiator）<br>local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程;<br>standalone(集群模式)：典型的Mater&#x2F;slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HA<br>on yarn(集群模式)： 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算<br>Spark运行架构包括：Master（集群资源管理）、Slaves（运行任务的工作节点）、应用程序的控制节点（Driver）和每个工作节点上负责任务的执行进程（Executor）；<br>2、Master是集群资源的管理者（Cluster Manager）。支持：Standalone,Yarn,Mesos；Slaves在spark中被称为Worker，工作节点，；<br>1.Spark的计算模式属于MapReduce,在借鉴Hadoop MapReduce优点的同时很好地解决了MapReduce所面临的问题<br>2.不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活<br>3.Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高<br>4.Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制(函数调用)<br>spark on yarn 的支持两种模式：<br>　　　yarn-cluster：适用于生产环境<br>　　　yarn-client：适用于交互、调试，希望立即看到app的输出<br>standalone模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。从一定程度上说，该模式是其他两种的基础。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/31/hello-world/"/>
      <url>/2022/05/31/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><div class="story post-story"><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p></div>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
